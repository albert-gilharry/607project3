---
title: "project3"
author: "group1"
date: "March 16, 2018"
output:
  html_document:
    theme: cerulean
    hightlight: tango
    css: styles.css
---

```{r setup, include=FALSE}
library(plyr)
library(tidyverse)
library(splitstackshape)
library(magrittr)
library(rlang)
library(gridExtra)
library(knitr)
library(kableExtra)
```

## Our Project {.tabset}

```{r, warning=FALSE, message=FALSE}
raw.data <- read_csv('https://raw.githubusercontent.com/brian-cuny/607project3/master/multipleChoiceResponses.csv', na=c('', 'NA')) %>%
  subset(DataScienceIdentitySelect == 'Yes' & CodeWriter == 'Yes') %>%
  rowid_to_column('id')
```

### Profile of a Data Scientist: Justin

Credit to Amber Thomas for providing the following code used for extracting and summarizing answer to multiple-choice questions.

```{r}
chooseOne = function(question){
    exp_df %>%
        filter(!UQ(sym(question)) == "") %>% 
        dplyr::group_by_(question) %>% 
        dplyr::summarise(count = n()) %>% 
        dplyr::mutate(percent = (count / sum(count)) * 100) %>% 
        dplyr::arrange(desc(count)) 
}

chooseMultiple = function(question,df){
  df %>% 
    dplyr::filter(!UQ(sym(question)) == "") %>%
    dplyr::select(question) %>% 
    dplyr::mutate(totalCount = n()) %>% 
    dplyr::mutate(selections = strsplit(as.character(UQ(sym(question))), 
                                 '\\([^)]+,(*SKIP)(*FAIL)|,\\s*', perl = TRUE)) %>%
    unnest(selections) %>% 
    dplyr::group_by(selections) %>% 
    dplyr::summarise(totalCount = max(totalCount),
              count = n()) %>% 
    dplyr::mutate(percent = (count / totalCount) * 100) %>% 
    dplyr::arrange(desc(count))
}        

Academic_exploration=function(question,df){
     df %>%
        filter(!UQ(sym(question)) == "") %>% 
        dplyr::group_by_(question) %>% 
        dplyr::summarise(count = n()) %>% 
        dplyr::mutate(percent = (count / sum(count)) * 100) %>% 
        dplyr::arrange(desc(count)) 
  }

proportion_function <- function(vec){
    vec/sum(vec)*100
}

create_breaks <- function(dfcolumn,breaks,labels){
    dfcolumn <- as.numeric(dfcolumn)
    dfcolumn <- cut(dfcolumn,breaks=breaks,labels=labels,right=FALSE)
}
```

The columns related to the demographics of this data was subset.

```{r pressure, warning=FALSE, message=FALSE}
exp_df <- raw.data%>%
    select(c(1:5,10,11,59,12,56,57,58,60,70,71,72,73,74,75,76,207,208,209))
```

```{r,echo=FALSE}
education <- chooseOne('FormalEducation')
other_count <- sum(education[4:7,]$count)
other_percent <- sum(education[4:7,]$percent)
Other <- c("Other",other_count,other_percent)

education.names <- c("Bachelor's degree", "Master's degree", "Doctoral degree", "Other")

education <- education %>% 
    filter(FormalEducation%in% c("Master's degree","Doctoral degree","Bachelor's degree")) %>% 
    rbind(.,Other)  
education[,2:3] <- sapply(education[,2:3], as.numeric) 
ggplot(education, aes(x=education.names, y=percent, fill=education.names)) + 
      geom_bar(stat="identity")+
      scale_fill_brewer(palette='Set1') + 
      theme(legend.position="none") + 
      xlim(education.names) + 
      labs(title='Most Data Scientists have at Least a Masters Degree',
           x='Highest Education Earned',
           y='Percent')
```

<img src="https://raw.githubusercontent.com/brian-cuny/607project3/master/scripts/burthworks_study_education_levels.PNG">
 
```{r,echo=FALSE}
majors <- chooseOne('MajorSelect') %>% 
  arrange(.,desc(percent))
majors[7,1] <- c("IT")
majors$MajorSelect <- factor(majors$MajorSelect, levels = majors$MajorSelect)
ggplot(majors, aes(x = MajorSelect,y=percent, fill = MajorSelect)) + 
      geom_bar(stat="identity") +
      theme(legend.position="none") +
      coord_flip() + 
      labs(title='Most Data Scietists come from a STEM Background',
           x='Major', 
           y='Percent')
```

```{r,echo=FALSE}
our_gender_data <- chooseOne('GenderSelect')
our_gender_data <-  our_gender_data %>% 
    select(GenderSelect,percent) 
our_gender_data[c(3,4),1]=c("other","Non-binary")
ggplot(our_gender_data, aes(x = GenderSelect,y=percent, fill = GenderSelect)) +
  geom_bar(stat="identity") +
  theme(legend.position="none") +
  labs(title='Men Outnumber Women 4:1',
       x='Gender',
       y='Percent')
```

<img src="https://raw.githubusercontent.com/brian-cuny/607project3/master/scripts/burthworks_study_gender_demographics.PNG">

```{r,echo=FALSE}
our_age<- create_breaks(exp_df$Age,c(1,22.1, 28.1,35.1,41.1,49.1,56.1,Inf ),c("18-22", "23-30", "31-38", "39-46 ", "47-54 ", "55-62","62+"))
exp_df["age_groups"] <-our_age 
chosen_age <- chooseOne('age_groups')
chosen_age <- chosen_age %>% 
    arrange(.,age_groups)

ggplot(chosen_age, aes(x = age_groups,y=percent, fill = age_groups)) + 
  geom_bar(stat="identity") +
  scale_fill_brewer(palette='Set1') + 
  theme(legend.position="none") + 
  labs(title='Data Scientists are Younger than the Average Worker',
       x='Age Group',
       y='Percent')
```

```{r,echo=FALSE}
burtchworks_tenure <- (c('0-5'=150,'6-10'=120,'11-15'=75,"16-20"=25,"21-25"=22,"26-30"=2,"31+"=1))

percent_Burtch_works <- proportion_function(burtchworks_tenure) 
names(percent_Burtch_works) <- c("percent")
burtchworks_tenure_df <- as_data_frame(cbind(burtchworks_tenure, percent_Burtch_works))
burtchworks_tenure_df$tenure <- c('0-5','6-10','11-15',"16-20","21-25","26-30","31+")

burtchworks_tenure_df$Tenures <- factor(burtchworks_tenure_df$tenure, levels = burtchworks_tenure_df$tenure)

my_tenure <- chooseOne("Tenure")

my_tenure$Tenure=c("3-5 Years","10+ Years","1-2 Years","6-10 Years", "< 1 Year", "Doesn't write code")
my_tenure$Tenures <- factor(my_tenure$Tenure, levels = my_tenure$Tenure)

ggplot(my_tenure, aes(x = Tenures,y=percent, fill = Tenures)) + 
      geom_bar(stat="identity")+
      scale_x_discrete("Tenures", limits=c( "< 1 Year","1-2 Years","3-5 Years","6-10 Years","10+ Years", "Doesn't write code")) +
      theme(legend.position="none") +
      scale_fill_brewer(palette='Set2') + 
      labs(title='Most Data Scientists are New to the Field',
           x='Tenure',
           y='Percent')
```

```{r, echo=FALSE}
percent_burchwood_tenure<- sum(as.numeric(burtchworks_tenure_df[3:7,]$percent_Burtch_works))
burchwood_tenure_N <-  sum(as.numeric(burtchworks_tenure_df[3:7,]$burtchworks_tenure))
extra_row <- c(burchwood_tenure_N,percent_burchwood_tenure," 10 + Years")

burtchworks_tenure_comparison_df <- burtchworks_tenure_df %>% 
    filter(tenure %in% c("0-5","6-10")) %>% 
    select(-Tenures) %>% 
    rbind(.,extra_row)  

burtchworks_tenure_comparison_df[,1:2] <- sapply(burtchworks_tenure_comparison_df[,1:2], as.numeric)

burtchworks_tenure_comparison_df$tenure <- factor(burtchworks_tenure_comparison_df$tenure, levels = burtchworks_tenure_comparison_df$tenure)

one_to_five <- c("0-5",sum(my_tenure[c(1,3,5),]$percent))
our_data_set_tenure_grouped <- rbind(one_to_five,my_tenure[4, c(1,3)],my_tenure[2, c(1,3)])

combined.data <- cbind(burtchworks_tenure_comparison_df[, c(3,2)], our_data_set_tenure_grouped[, 2]) %>%
  setNames(c('Tenure', 'Burtchworks', 'Our Data')) %>%
  gather('data', 'percent', 2:3)

ggplot(combined.data, aes(x=Tenure, y=percent %>% as.numeric() %>% plyr::round_any(1), fill=data)) +
  geom_bar(stat='identity', position='dodge') + 
    scale_fill_brewer(palette='Paired') + 
    labs(title='Our Data Set is Less Experienced Than Average',
         x='Tenure',
         y='Percent',
         fill='Data Set')
```

```{r, echo=FALSE}
EmployerIndustries <- chooseOne("EmployerIndustry") 
EmployerIndustries$EmployerIndustry <- factor(EmployerIndustries$EmployerIndustry, levels=EmployerIndustries$EmployerIndustry)
EmployerIndustries %>% 
    filter(EmployerIndustry%in%c("Academic", "Technology", "Financial", "Other", "Mix of fields", "Internet-based", "Government", "Manufacturing", "CRM/Marketing", "Insurance", "Retail", "Pharmaceutical", "Non-profit", "Military/Security", "Hospitality/Entertainment/Sports")) %>% 
ggplot(., aes(x = EmployerIndustry,y=percent, fill = EmployerIndustry)) + 
      geom_bar(stat="identity")+
      theme(legend.position="none")+
      coord_flip() +
      labs(title='Data Scientists Work in a Range of Fields',
             x='Industry',
             y='Percent'
           )
```

```{r, echo=FALSE}
US_only_df <- exp_df %>% 
    filter(Country%in%c('United States'))
    
US_only_df$CompensationAmount <- str_replace_all(US_only_df$CompensationAmount,"\\D+","") 

us_money <- Academic_exploration("CompensationAmount",US_only_df)
my_dat <- create_breaks(us_money$CompensationAmount,breaks=c(0,30000,70000,11000,150000,Inf),labels=c('<30k','30-70k',"70-110k","110-150k","150k+"))
us_money$groups <- my_dat

ggplot(us_money, aes(x=groups, y=percent, fill=groups)) + 
        geom_bar(stat="identity")+
        theme(legend.position="none")+
        scale_x_discrete("Compensation", limits=c('<30k','30-70k',"70-110k","110-150k","150k+")) +
        scale_fill_brewer(palette='Set2') + 
        labs(title='Data Scientists Are Well Compensated',
             y='Percent'
           )
```

### Learning Platform Usefulness: Hovig



### Learning Categories: Brian

This subset of data examines how data scientists learned their core skill set. Each data scientist was asked to assign each category a percent from 0 to 100 indicating how much of their education was made up of this source.

First, a list of categories was extrated and formatted.

```{r}
tidy.names <- names(raw.data)[61:66] %>% 
  str_extract('(?<=LearningCategory)(\\w+)') %>% 
  str_replace_all('(?<=[a-z])([A-Z])', '_\\1') %>% 
  tolower()
tidy.names %>% kable()
```

The data was tidied and the categories were converted to factors, to aid in analysis.

```{r}
tidy.data <- raw.data %>%
  select(c(1, 61:66)) %>%
  setNames(c('id', tidy.names)) %>%
  gather('category', 'percent', 2:7, na.rm=TRUE)

tidy.data$percent %<>% as.numeric()

tidy.data$category %<>% factor(levels=tidy.names, ordered=TRUE)
tidy.data %>% head(10) %>% kable()
```

Summary statistics tell an intersting story. No source averaged more than 50% of the sets learning sources. This would seem to indicate that data scientists learn from a diverse set of sources. The 'other' category's mean is nearly 0 also indicating that the other categories account for nearly all learning sources. 

```{r}
tidy.summary.data <- tidy.data %>% 
  group_by(category) %>% 
  summarise(avg=mean(percent), sd=sd(percent))
tidy.summary.data %>% kable()
```

The boxplots support the summary statistics. Each category has numerous upper ourliers indicating that data scientists who learned most or entirely from one source were rare.

```{r}
ggplot(tidy.data) +
  geom_boxplot(aes(category, percent)) +
  xlim(tidy.names %>% rev()) +
  coord_flip() + 
  labs(x='Learning Source', 
       y='Proportion',
       title='Data Scientists Learn From Diverse Sources'
  )
```

The final more clearly shows the diversity in learning styles. This indicates that not only do data scientists learn from a variety of sources, but every data scientist's sources vary in importance. This highlights the idea that there is not right or wrong way to learn to become a data scientist. At the same time, as the four major categories amount for nearly 100% of education, this means that there are no "secret" learning sources.

```{r}
ggplot(tidy.data) +
  geom_bar(aes(category, fill=percent %>% 
                                round_any(10) %>% 
                                factor(seq(0, 100, 10))
              ), position=position_fill(reverse=TRUE)
          ) +
  scale_color_brewer(palette='Set1') + 
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  labs(x='Learning Source', 
       y='Proportion',
       title='Data Scientists Learn From Diverse Sources',
       fill='Percent'
  )
```

### Common Job Algorithms: Rose

This subset of data examines common algorithms and methods used by data scientists.

First, the proper data is subset.

```{r}
data.rose <- raw.data %>%
  select(c(1, 80:81, 134:167))

tidy.names <- c(names(data.rose)[1:4], 
                names(data.rose)[5:37] %>% 
                  str_extract('(?<=WorkMethodsFrequency)(.+)')
                )

melt.dt <- data.rose %>%
  setNames(tidy.names) %>%
  gather('WorkMethodsFrequency', 'Frequency', 5:37)
```

The data on commonly used algorithms was seperated into it's own table.

```{r}
alg.select <- melt.dt %>%
  select(c('id', 'WorkAlgorithmsSelect'))
alg.select.list <- alg.select$WorkAlgorithmsSelect %>%
  strsplit(split = ",")
alg.select.dt <- tibble(id = rep(alg.select$id, sapply(alg.select.list, length)), 
                            algorithm = unlist(alg.select.list))
alg.select.dt %>% head(10) %>% kable()
```

The data on commonly used method was seperated into it's own table.

```{r}
method.select <- melt.dt %>%
  select(c('id', 'WorkMethodsSelect'))
method.select.list <- method.select$WorkMethodsSelect %>%
  as.character() %>% 
  strsplit(split = ",")
method.select.dt <- tibble(id = rep(method.select$id, sapply(method.select.list, length)), 
                               method = unlist(method.select.list))
method.select.dt %>% head(10) %>% kable()
```

Finally, the data on fequency of each method was seperated into it's own table.

```{r}
freq.dt <- melt.dt %>%
  select(c('id', 'WorkDatasetSize', 'WorkMethodsFrequency', 'Frequency'))
freq.dt %>% head(10) %>% kable()
```

```{r}
alg.select.dt <- as.data.table(alg.select.dt)
alg.total <- nrow(na.omit(alg.select.dt))
alg.vis <- na.omit(alg.select.dt)[, .(count = length(id)), by = .(algorithm)][order(-count)]
alg.vis$perc <- paste0(round((alg.vis$count / alg.total) * 100, 2), "%")

ggplot(alg.vis, aes(reorder(algorithm, count), count, fill = algorithm)) + 
  geom_text(aes(label = perc), hjust = -0.5, size = 3, color = "black") +
  guides(fill=FALSE) +
  geom_bar(stat = 'identity') +
  coord_flip() + 
  labs(title = "Algorithm used by data scientists",
       x = "Algorithm",
       y = "Proportion") 
```

```{r}
method.select.dt <- as.data.table(method.select.dt)
method.total <- nrow(na.omit(method.select.dt))
method.vis <- na.omit(method.select.dt)[, .(count = length(id)), by = .(method)][order(-count)]
method.vis$perc <- paste0(round((method.vis$count / method.total) * 100, 2), "%")

ggplot(method.vis, aes(reorder(method, count), count, fill = method)) + 
  geom_text(aes(label = perc), hjust = -0.5, size = 3, color = "black") +
  guides(fill=FALSE) +
  geom_bar(stat = 'identity') +
  coord_flip() + 
  labs(title = "Method used by data scientists",
       x = "Method",
       y = "Proportion") 
```

```{r}
freq.dt <- as.data.table(freq.dt)
freq.dt <- freq.dt[, .(count = .N), by = .(Frequency, WorkMethodsFrequency,WorkDatasetSize)]
method.freq <- freq.dt[, .(count = sum(count)), by = .(WorkMethodsFrequency, Frequency)][order(-count)]
size.freq <- freq.dt[, .(count = sum(count)), by = .(WorkDatasetSize, Frequency)][order(-count)]

ggplot(na.omit(size.freq), aes(reorder(WorkDatasetSize, count), count, fill = WorkDatasetSize)) +
  guides(fill=FALSE) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle= 90, hjust=1)) +
  coord_flip() +
  facet_wrap(~Frequency) +
  labs(title = "Datasetsize used by frequency",
       x = "Dataset Size",
       y = "Count")
```

```{r, fig.height=8}
ggplot(na.omit(freq.dt[count>25]), aes(reorder(WorkMethodsFrequency, count), count, fill = WorkMethodsFrequency)) +
  guides(fill=FALSE) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle= 90, hjust=1)) +
  coord_flip() +
  facet_wrap(~WorkDatasetSize) +
  labs(title = "Method Used Per Data Size",
       x = "Work Methods",
       y = "Count")
```

### Work Tools Freqeuncy: Meaghan

The data was very untidy and expanded into two columns passed the "WorkToolsSelect" column. I brought in the 3 columns and replaced elements to ensure a easy split 

```{r message=FALSE, warning=FALSE}
tidy.names <- names(raw.data)[83:132]%>% 
  str_extract('(?<=WorkToolsFrequency)(\\w+)') %>% 
  str_replace_all('(?<=[a-z])([A-Z])', '_\\1') 

tools.data <- raw.data %>%
  select(c(1, 82:84)) %>%
  setNames(c('id', 'tool_used', "temp_1", "temp_2"))%>%
  unite_("tool_used", c("tool_used","temp_1","temp_2"))%>%
  mutate(tool_used = (str_replace_all(tool_used, '/', ',')),
         tool_used = (str_replace_all(tool_used, '_', ',')))%>%
  mutate(tool_counter =1)
tools.data <- cSplit(tools.data, 'tool_used', ',')
```

I used the gather function to reformat the table

```{r message=FALSE, warning=FALSE}
id.tool.df <- tools.data %>%
  gather(tool_group, tool, names(tools.data)[3:63])%>%
  group_by(id, tool)%>%
  summarise(sum_tool = sum(tool_counter))%>%
  drop_na()%>%
  filter(!tool %in% c("Rarely", "Often",
                      "Sometimes", "Most of the time"))
id.tool.df %>% head(10) %>% kable()
```

I created a summary table representing the frequency of each response.

```{r message=FALSE, warning=FALSE}
summary.tool.df <- tools.data %>%
  gather(tool_group, tool, names(tools.data)[3:63])%>%
  group_by(tool)%>%
  summarise(sum_tool = sum(tool_counter))%>%
  drop_na()%>%
  arrange(desc(sum_tool))%>%
  filter(!tool %in% c("Rarely", "Often",
                      "Sometimes", "Most of the time"))%>%
  mutate(percent_total = round((sum_tool/ sum(sum_tool))*100,digits = 2))
summary.tool.df %>% head(10) %>% kable()
```

This plot shows the top data science skills given the filters used.

```{r }
ggplot(head(summary.tool.df,15), aes(x=reorder(tool, -sum_tool), y=percent_total)) + 
  geom_bar(stat="identity", width=.5, fill="tomato3") +
  geom_text(aes(label=percent_total))+
  labs(x='Tool', 
       y='Percent Total',
       title="Top 15 Data Science Tools", 
       caption="Source: Multiple Choice Responses") + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))
```

A data frame of tool frequency by id was created.

```{r}
frequency.data <- raw.data %>%
  select(c(1, 83:132)) %>%
  setNames(c('id', tidy.names))

id.frquency.table <-frequency.data %>% 
  gather(tool_name, frequency_id, names(frequency.data)[2:51])%>%
  filter(frequency_id %in% c("Rarely", "Often",
                             "Sometimes", "Most of the time"))%>%
  arrange(id)
id.frquency.table %>% head(10) %>% kable()
```

I grouped the frequency information by the actual tool name & response 

```{r}
summary.frquency.table <- frequency.data %>% 
  gather(tool_name, frequency_id, names(frequency.data)[2:51])%>%
  filter(frequency_id %in% c("Rarely", "Often",
                             "Sometimes", "Most of the time"))%>%
  mutate(freq_counter =1) %>%
  group_by(tool_name,frequency_id)%>%
  summarise(sum_feq = sum(freq_counter))%>%
  arrange(desc(sum_feq))
summary.frquency.table %>% head(10) %>% kable()
```

The plot shows frequency of use of top technologies.

```{r}
ordering <- c('Most of the time', 'Often', 'Sometimes', 'Rarely')

ggplot(head(summary.frquency.table,50), aes(x = frequency_id, y = sum_feq, fill = tool_name)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~tool_name) + 
  ylab("Number of times a response was selected") + 
  xlim(ordering) +
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5, 
                                   hjust = 1))
```



### Work Challenges: Albert

This subset of the data addresses the challenges faced by Data Scientists, and how their time is typically spent at work. 

The Data Scientists were asked to select the challenges (from a predefined list) they encounter at work. They also indicated the frequency (from a predefined list) at which these challenges were faced.
Responders were also asked to indicate the ratio of time spent performing key Data Science tasks including data gathering, model building, production, visualizing, finding insiights, and `other`.

## Tidy & Transform

** Create `challenges` table to store challenges faced by each Data Scientist **

```{r}
# Create table to store challenges in long format
challenges <- raw.data %>% 
  select(id, "WorkChallengesSelect") %>% 
  cSplit("WorkChallengesSelect", sep = ",", direction = "long") # split cells containing comma delimited values into rows
```


** Create `challenges.frequency` table to store the frequency at which these challenges were faced **

```{r}
# Create table in long format
challenges.frequency <- raw.data %>%  
  select(id, starts_with("WorkChallenge"), -WorkChallengesSelect) %>%
  gather("WorkChallengeFrequency", "Frequency", -id )
```


** Create `time.spent` table to store the distribution of time spent **

```{r}
# Create table in long format
time.spent <- raw.data %>%  
  select(id, starts_with("Time"), - TimeSpentStudying) %>%
  gather("Activity", "Time", -id )
```

** Create CSVs for database import **

```{r}
# Create CSV for `challenges` table
write.csv(challenges, file = "../tidied_csv/challenges.csv", row.names = FALSE, quote = FALSE)

# Create CSV for `challenges.frequency` table
write.csv(challenges.frequency, file = "../tidied_csv/challenges.frequency.csv", row.names = FALSE, quote = FALSE)

# Create CSVs for `time.spent` table
write.csv(time.spent, file = "../tidied_csv/time.spent.csv", row.names = FALSE, quote = FALSE)
```

## Analysis

**Distribution of time spent**
```{r}
# Plot: Distribution of Time Spent
filter( time.spent, !is.na(`Time`), `Time` != 'NA') %>% 
  mutate(`Time` = as.integer(`Time`)) %>% 
  group_by(`Activity`) %>% 
  summarise(`Time`= round(mean(`Time`), digits = 2)) %>% 
    ggplot(aes(x = Activity, y = Time,fill=Activity, label = `Time`) ) + 
      geom_bar(stat = "identity", show.legend = F) + 
      geom_text(size = 2, position = position_stack(vjust = 0.5)) + 
      coord_flip() +  
      labs(title = "Distribution of Time Spent")
```

**Below is a quick reference to the meaning of each activity in the plot.**

TimeGatheringData -> Gathering and cleaning data
TimeModelBuilding -> Model building/model selection
TimeProduction -> Putting your work into production
TimeVisualizing -> Visualizing data
TimeFindingInsights -> Finding insights in the data and communicating these to relevant stakeholders
TimeOtherSelect -> Other

The plot shows that Data Scientists spend majority of their time cleaning and gathering data, and selecting/building models. 
These two activities account for over 58% of Data Scientists time on average. Preparing visualizations and finding and communicating insights accounts for 27% of the Data Scientists time, when grouping these relevant activities. This is evidence that **soft skills** play a key role for Data Scientists.

```{r}
# Plot: Challenges at Work
  ggplot(data = challenges, aes(challenges$WorkChallengesSelect,fill=WorkChallengesSelect)) + 
  geom_histogram( stat='count', show.legend = F ) + 
  coord_flip() +  
  labs( title = "Challenges at Work", x = "Challenges", y = "Count" )
```

```{r}
# Frequency of Workplace Challenges
  filter( challenges.frequency, !is.na(`Frequency`) ) %>% 
  group_by(`WorkChallengeFrequency`, `Frequency`) %>% 
  summarise(`Count`= n()) %>% 
  mutate(`Ratio` = round(  ( `Count` / sum( `Count` ) ) * 100, digits = 2 ) ) %>% 
  factor( `Frequency`, levels = c("Most of the time", "Often" , "Sometimes", "Rarely") ) 
  ggplot(c,aes( x = WorkChallengeFrequency, y = Ratio, fill = Frequency,label = Ratio ) ) + 
  geom_bar( stat = "identity" ) + 
  geom_text(size = 2, position = position_stack(vjust = 0.5)) + 
  coord_flip() +  
  scale_fill_brewer(palette = 'RdYlBu') + 
  labs( title = "Frequency of Workplace Challenges", x = "Challenge", y = "Frequency" )
```

### Conclusion (writing to csv/importing to sql?)

























